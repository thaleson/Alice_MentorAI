import streamlit as st
from app.interfaces.llm_interface import ask_llm



st.set_page_config(page_title="Revis√£o Inteligente", page_icon="üìö")
st.title("üß† Alice MentorAI ,IA para Revis√£o de Concursos")

# Aplicar estilos de CSS √† p√°gina (se houver)
try:
    with open("static/styles.css") as f:
        st.markdown(f'<style>{f.read()}</style>', unsafe_allow_html=True)
except FileNotFoundError:
    st.warning("Arquivo de estilo CSS n√£o encontrado!")

    
st.markdown(
    """
    Digite seu resumo ou conte√∫do de estudo.  
    A IA ir√° indicar o **melhor m√©todo de revis√£o**: flashcards, mapas mentais, quest√µes, etc.
    """
)

# Seletor de tom
tone = st.selectbox(
    "üéØ Escolha o tom da resposta da IA:",
    ["T√©cnico", "Motivacional", "Divertido"]
)

# Inicializa hist√≥rico
if "messages" not in st.session_state:
    st.session_state.messages = []

# Exibe hist√≥rico
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# Entrada do usu√°rio
if prompt := st.chat_input("Digite seu conte√∫do de estudo aqui..."):
    # Adiciona prompt do usu√°rio
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # Ajusta prompt com base no tom selecionado
    if tone == "T√©cnico":
        tone_prompt = (
            "Responda com uma an√°lise objetiva e fundamentada em m√©todos de aprendizado eficazes para concursos."
        )
    elif tone == "Motivacional":
        tone_prompt = (
            "Responda com energia positiva, incentivando a pessoa e indicando m√©todos eficazes de revis√£o."
        )
    elif tone == "Divertido":
        tone_prompt = (
            "Responda com bom humor, mantendo a clareza, e recomende formas divertidas de revisar o conte√∫do."
        )

    full_prompt = f"{tone_prompt}\n\nConte√∫do:\n{prompt}"

    with st.chat_message("assistant"):
        with st.spinner("‚öôÔ∏è Processando seu material com foco em m√©todos de revis√£o eficientes..."):
            response = ask_llm(full_prompt)
            st.markdown(f"**Alice MentorAI:** {response}")

    # Adiciona resposta da IA
    st.session_state.messages.append({"role": "assistant", "content": response})
